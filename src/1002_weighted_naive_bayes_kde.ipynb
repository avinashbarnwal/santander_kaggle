{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from   sklearn.base            import BaseEstimator, ClassifierMixin\n",
    "from   sklearn                 import datasets\n",
    "import numpy                   as     np\n",
    "from   sklearn.neighbors       import KernelDensity\n",
    "from   sklearn.model_selection import GridSearchCV\n",
    "from   sklearn.model_selection import KFold\n",
    "from   sklearn.model_selection import train_test_split\n",
    "from   sklearn.metrics         import roc_auc_score,roc_curve,auc\n",
    "import utils\n",
    "import multiprocessing         as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://jakevdp.github.io/PythonDataScienceHandbook/05.13-kernel-density-estimation.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KDEClassifier(BaseEstimator, ClassifierMixin):\n",
    "    \n",
    "    \"\"\"Bayesian generative classification based on KDE\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    bandwidth : float\n",
    "        the kernel bandwidth within each class\n",
    "    kernel : str\n",
    "        the kernel name, passed to KernelDensity\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, bandwidth=1.0,k=5,kernel='gaussian'):\n",
    "        \n",
    "        self.bandwidth = bandwidth\n",
    "        self.kernel    = kernel\n",
    "        self.k         = 5\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \n",
    "        self.classes_   = np.sort(np.unique(y))\n",
    "        training_sets   = [X[y == yi] for yi in self.classes_]\n",
    "        print(len(training_sets))\n",
    "        self.models_    = [KernelDensity(bandwidth=self.bandwidth,\n",
    "                                      kernel=self.kernel).fit(Xi)\n",
    "                           for Xi in training_sets]\n",
    "        \n",
    "        #self.logpriors_ = [np.log(Xi.shape[0] / X.shape[0])\n",
    "        #                   for Xi in training_sets]\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def each_prior_prob(self,x,X,y):\n",
    "        \n",
    "        \n",
    "        dist          = [np.linalg.norm(x-xi) for xi in X]\n",
    "        anchor_k      = sorted(dist)[self.k]\n",
    "        dist_adj_k    = dist/anchor_k\n",
    "        weight_k      = list(map(lambda x: 0 if x >= 1 else 1- x,dist_adj_k))\n",
    "        indicator     = [y==i for i in set(y)]\n",
    "\n",
    "        n             = len(set(y))\n",
    "        indic_weight  = [indicator[i]*weight_k for i in range(n)]\n",
    "        new           = np.hstack([np.expand_dims(indic_weight[0], axis=1), np.expand_dims(indic_weight[1], axis=1)])\n",
    "\n",
    "        if n >2:\n",
    "            for i in range(2,n):\n",
    "                new       = np.hstack([new, np.expand_dims(indic_weight[i], axis=1)])\n",
    "                \n",
    "        prob_weight       = [sum(new[:,i]) for i in range(n)]\n",
    "        weight_sum        = sum(weight_k)\n",
    "        log_prob_prior    = np.log(list(map(lambda x: 0+0.000001 if x==0 else x/weight_sum,prob_weight)))\n",
    "        \n",
    "        return log_prob_prior\n",
    "    \n",
    "    \n",
    "    def prior_prob_fit(self,X_test,X_train,y):\n",
    "    \n",
    "        n                 = len(set(y))\n",
    "        prior_prob        = np.zeros((X_test.shape[0],n),dtype=np.float32)\n",
    "        \n",
    "        #kfold             = 50\n",
    "        #mp_pool           = mp.Pool(kfold)\n",
    "        \n",
    "        \n",
    "        \n",
    "        for i in range(X_test.shape[0]):\n",
    "            prior_prob[i] = self.each_prior_prob(X_test[i],X_train,y)\n",
    "        \n",
    "        #prior_prob        = []\n",
    "        #prior_prob.extend(mp_pool.starmap(self.each_prior_prob, zip(parent_data.values(),np.repeat(ss,no_of_targets),parent_data.keys(),np.repeat(error_type,no_of_targets))))\n",
    "        \n",
    "        #mp_pool.close()\n",
    "        #mp_pool.join()\n",
    "        \n",
    "        return prior_prob\n",
    "    \n",
    "    def predict_proba(self,X_valid,X_train,y_train):\n",
    "        \n",
    "\n",
    "        logprobs        = np.array([model.score_samples(X_valid)\n",
    "                             for model in self.models_]).T\n",
    "        self.logpriors_ = self.prior_prob_fit(X_valid,X_train,y_train)\n",
    "        result          = np.exp(logprobs + self.logpriors_)\n",
    "        \n",
    "        \n",
    "        print(logprobs)\n",
    "        print(self.logpriors_)\n",
    "        print(result)\n",
    "        return result/result.sum(1, keepdims=True)\n",
    "        \n",
    "    def predict(self, X_valid,X_train,y_train):\n",
    "        return self.classes_[np.argmax(self.predict_proba(X_valid,X_train,y_train), 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_dataset():\n",
    "    ris    = datasets.load_iris()\n",
    "    df_train, df_test, target_train, target_test = train_test_split(iris.data, iris.target, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris    = datasets.load_iris()\n",
    "df_train, df_test, target_train, target_test = train_test_split(iris.data, iris.target, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_param():\n",
    "    \n",
    "    hyper_parameter               = {}\n",
    "    hyper_parameter['bandwidths'] = 10 ** np.linspace(0, 2, 2)\n",
    "    hyper_parameter['k']          = np.arange(5,6)\n",
    "    \n",
    "    # Compute ROC curve and ROC area for each class\n",
    "    \n",
    "    fpr                           = dict()\n",
    "    tpr                           = dict()\n",
    "    roc_auc                       = dict()\n",
    "    \n",
    "    return hyper_parameter,fpr,tpr,roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GridSearchCV_w_bayes(df_train,target_train,nFolds = 5,random_state = 0,shuffle=True,hyper_parameter=None):\n",
    "    \n",
    "    bandwidths = hyper_parameter['bandwidths']\n",
    "    k          = hyper_parameter['k']\n",
    "    \n",
    "    for bandwidth in bandwidths:\n",
    "        for k_iter in k:\n",
    "            \n",
    "            kf           = KFold(n_splits=nFolds, random_state=random_state, shuffle=shuffle)\n",
    "            roc_auc_iter = 0\n",
    "            \n",
    "            for train_index, valid_index in kf.split(df_train):\n",
    "                \n",
    "                X_train, X_valid = df_train[train_index],df_train[valid_index]\n",
    "                y_train, y_valid = target_train[train_index], target_train[valid_index]\n",
    "                model            = KDEClassifier(bandwidth=bandwidth,k=k_iter)\n",
    "                model.fit(X_train,y_train)\n",
    "                predicted        = model.predict_proba(X_valid,X_train,y_train)\n",
    "                n_classes        = len(set(y_train))\n",
    "                y_valid_iter     = np.zeros((y_valid.shape[0],n_classes))\n",
    "                \n",
    "                print(y_valid)\n",
    "                print(\"predicted\")\n",
    "                print(predicted)\n",
    "                for i in range(n_classes):\n",
    "                    y_valid_iter[:,i]    =  y_valid==i\n",
    "                    fpr[i], tpr[i], _    =  roc_curve(y_valid_iter[:,i], predicted[:, i])\n",
    "                    roc_auc_iter         += auc(fpr[i], tpr[i])/n_classes\n",
    "\n",
    "            roc_auc_iter                 = roc_auc_iter/nFolds        \n",
    "            roc_auc[(bandwidth,k_iter)]  = roc_auc_iter\n",
    "            \n",
    "    best_bandwidth,best_k = sorted(roc_auc.items(),key = lambda k:-k[1])[0][0],sorted(roc_auc.items(),key = lambda k:-k[1])[0][1]\n",
    "    return best_bandwidth,best_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_parameter,fpr,tpr,roc_auc = init_param()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#best_bandwidth,best_k           = GridSearchCV_w_bayes(df_train=df_train,target_train = target_train,nFolds = 5,random_state = 0,shuffle=True,hyper_parameter=hyper_parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 27.91it/s]\n"
     ]
    }
   ],
   "source": [
    "train_path        = '../data/input/input_pkl/train/'\n",
    "train             = utils.read_pickles(train_path)\n",
    "#train             = train[0:20000]  \n",
    "target            = train.target.values\n",
    "train.drop(['target','ID_code'], axis=1, inplace=True)\n",
    "\n",
    "train             = train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 30.29it/s]\n"
     ]
    }
   ],
   "source": [
    "test_path         = '../data/input/input_pkl/test/'\n",
    "test              = utils.read_pickles(test_path) \n",
    "test              = test.values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((200, 200), (200,), (100, 201))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, target.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "[[-4413.04678523 -4659.47607688]\n",
      " [-3921.75970032  -220.87706755]\n",
      " [-3390.67368014 -3623.2277422 ]\n",
      " ...\n",
      " [-4229.41926446 -4060.09136068]\n",
      " [ -219.88069938 -4645.77518829]\n",
      " [ -223.03574787 -4629.54773583]]\n",
      "[[  0.         -13.815511  ]\n",
      " [  0.         -13.815511  ]\n",
      " [  0.         -13.815511  ]\n",
      " ...\n",
      " [ -0.14748399  -1.9868715 ]\n",
      " [  0.         -13.815511  ]\n",
      " [  0.         -13.815511  ]]\n",
      "[[0.00000000e+000 0.00000000e+000]\n",
      " [0.00000000e+000 1.18661081e-102]\n",
      " [0.00000000e+000 0.00000000e+000]\n",
      " ...\n",
      " [0.00000000e+000 0.00000000e+000]\n",
      " [3.21384985e-096 0.00000000e+000]\n",
      " [1.37026774e-097 0.00000000e+000]]\n",
      "[0 0 0 ... 0 0 0]\n",
      "predicted\n",
      "[[nan nan]\n",
      " [ 0.  1.]\n",
      " [nan nan]\n",
      " ...\n",
      " [nan nan]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-83-6df46c35f735>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbest_bandwidth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbest_k\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV_w_bayes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnFolds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhyper_parameter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhyper_parameter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-73-187f3b7911a3>\u001b[0m in \u001b[0;36mGridSearchCV_w_bayes\u001b[0;34m(df_train, target_train, nFolds, random_state, shuffle, hyper_parameter)\u001b[0m\n\u001b[1;32m     25\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m                     \u001b[0my_valid_iter\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m    \u001b[0;34m=\u001b[0m  \u001b[0my_valid\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                     \u001b[0mfpr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m    \u001b[0;34m=\u001b[0m  \u001b[0mroc_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_valid_iter\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m                     \u001b[0mroc_auc_iter\u001b[0m         \u001b[0;34m+=\u001b[0m \u001b[0mauc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mn_classes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/metrics/ranking.py\u001b[0m in \u001b[0;36mroc_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[1;32m    616\u001b[0m     \"\"\"\n\u001b[1;32m    617\u001b[0m     fps, tps, thresholds = _binary_clf_curve(\n\u001b[0;32m--> 618\u001b[0;31m         y_true, y_score, pos_label=pos_label, sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m     \u001b[0;31m# Attempt to drop thresholds corresponding to points in between and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/metrics/ranking.py\u001b[0m in \u001b[0;36m_binary_clf_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    401\u001b[0m     \u001b[0my_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m     \u001b[0massert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m     \u001b[0massert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36massert_all_finite\u001b[0;34m(X, allow_nan)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0mallow_nan\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \"\"\"\n\u001b[0;32m---> 68\u001b[0;31m     \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan)\u001b[0m\n\u001b[1;32m     54\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[1;32m     55\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'infinity'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'NaN, infinity'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg_err\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "best_bandwidth,best_k   = GridSearchCV_w_bayes(df_train=train,target_train = target,nFolds = 5,random_state = 0,shuffle=True,hyper_parameter=hyper_parameter)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
